{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import itertools\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn import metrics\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn import metrics, svm, neighbors, linear_model, tree\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read data from file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\Katelyn\\\\Documents'"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Katelyn\\Documents\n"
     ]
    }
   ],
   "source": [
    "cd /Users/Katelyn/Documents/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>AskPrice</th>\n",
       "      <th>AskSize</th>\n",
       "      <th>BidPrice</th>\n",
       "      <th>BidSize</th>\n",
       "      <th>VOI</th>\n",
       "      <th>OIR</th>\n",
       "      <th>Spread</th>\n",
       "      <th>PriceChange</th>\n",
       "      <th>MPB</th>\n",
       "      <th>VOI_Norm</th>\n",
       "      <th>OIR_Norm</th>\n",
       "      <th>MPB_Norm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018-07-16 07:00:00-05:00</td>\n",
       "      <td>280325</td>\n",
       "      <td>118</td>\n",
       "      <td>280300</td>\n",
       "      <td>74</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.229167</td>\n",
       "      <td>25</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-0.009167</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018-07-16 07:00:00.100000-05:00</td>\n",
       "      <td>280300</td>\n",
       "      <td>85</td>\n",
       "      <td>280275</td>\n",
       "      <td>35</td>\n",
       "      <td>-85</td>\n",
       "      <td>-0.416667</td>\n",
       "      <td>25</td>\n",
       "      <td>-25</td>\n",
       "      <td>-12.5</td>\n",
       "      <td>-3.40</td>\n",
       "      <td>-0.016667</td>\n",
       "      <td>-0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018-07-16 07:00:00.200000-05:00</td>\n",
       "      <td>280300</td>\n",
       "      <td>81</td>\n",
       "      <td>280275</td>\n",
       "      <td>49</td>\n",
       "      <td>18</td>\n",
       "      <td>-0.246154</td>\n",
       "      <td>25</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.72</td>\n",
       "      <td>-0.009846</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2018-07-16 07:00:00.300000-05:00</td>\n",
       "      <td>280300</td>\n",
       "      <td>81</td>\n",
       "      <td>280275</td>\n",
       "      <td>49</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.246154</td>\n",
       "      <td>25</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-0.009846</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2018-07-16 07:00:00.400000-05:00</td>\n",
       "      <td>280300</td>\n",
       "      <td>81</td>\n",
       "      <td>280275</td>\n",
       "      <td>49</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.246154</td>\n",
       "      <td>25</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-0.009846</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               Time  AskPrice  AskSize  BidPrice  BidSize  \\\n",
       "0         2018-07-16 07:00:00-05:00    280325      118    280300       74   \n",
       "1  2018-07-16 07:00:00.100000-05:00    280300       85    280275       35   \n",
       "2  2018-07-16 07:00:00.200000-05:00    280300       81    280275       49   \n",
       "3  2018-07-16 07:00:00.300000-05:00    280300       81    280275       49   \n",
       "4  2018-07-16 07:00:00.400000-05:00    280300       81    280275       49   \n",
       "\n",
       "   VOI       OIR  Spread  PriceChange   MPB  VOI_Norm  OIR_Norm  MPB_Norm  \n",
       "0    0 -0.229167      25            0   0.0      0.00 -0.009167       0.0  \n",
       "1  -85 -0.416667      25          -25 -12.5     -3.40 -0.016667      -0.5  \n",
       "2   18 -0.246154      25            0   0.0      0.72 -0.009846       0.0  \n",
       "3    0 -0.246154      25            0   0.0      0.00 -0.009846       0.0  \n",
       "4    0 -0.246154      25            0   0.0      0.00 -0.009846       0.0  "
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"Order_Imbalance_Data.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Y = ['PriceChange']\n",
    "attributes = ['VOI, OIR, MPB']\n",
    "#Calculate each attribute and output into .csv file\n",
    "X = ['attributes'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Y = df['PriceChange']\n",
    "#features = ['VOI' , 'OIR' , 'MPB']\n",
    "#features_ind = list(range(800, 70))\n",
    "#X = df[features_ind]\n",
    "#feature_names = X.columns.tolist()\n",
    "#print(len(feature_names))\n",
    "#print(feature_names)\n",
    "#X.head()\n",
    "\n",
    "#Add to this later "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# features analysis\n",
    "def select_features(X, Y, plot=False):\n",
    "    forest = ExtraTreesClassifier(n_estimators=250,\n",
    "                              random_state=0)\n",
    "    \n",
    "    feature_names = X.columns.tolist()\n",
    "\n",
    "\n",
    "    forest.fit(X, Y)\n",
    "    importances = forest.feature_importances_\n",
    "    std = np.std([tree.feature_importances_ for tree in forest.estimators_],\n",
    "             axis=0)\n",
    "    indices = np.argsort(importances)[::-1]\n",
    "    \n",
    "    importances = np.array(importances)\n",
    "    importances /= importances.max()\n",
    "\n",
    "    if plot:\n",
    "        for f in range(X.shape[1]):\n",
    "            print(\"%d. feature '%s' (%f)\" % (f + 1, feature_names[indices[f]], importances[indices[f]]))\n",
    "\n",
    "\n",
    "        # Plot the feature importances of the forest\n",
    "        plt.figure()\n",
    "        plt.title(\"Feature importances\")\n",
    "        plt.bar(range(X.shape[1]), importances[indices], color=\"r\", yerr=std[indices], align=\"center\")\n",
    "        plt.xticks(range(X.shape[1]), indices)\n",
    "        plt.xlim([-1, X.shape[1]])\n",
    "        plt.show()\n",
    "        \n",
    "    # select features > 25 % importance\n",
    "    features = [i for i,j in zip(feature_names,importances) if j > 0.25]\n",
    "\n",
    "    print (\"Selected number of features: %d\" % len(features))\n",
    "\n",
    "    if plot:\n",
    "        for f in range(len(features)):\n",
    "            print(\"%d. feature %s (%f)\" % (f + 1, feature_names[indices[f]], importances[indices[f]]))\n",
    "        \n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[   0.     -25.      -1.25    -2.5     -3.75    -5.      -6.25    -7.5\n",
      "   -8.75   -10.     -11.25   -12.5    -13.75   -16.25   -18.75   -21.25\n",
      "  -23.75   -26.25   -28.75   -31.25   -33.75   -40.     -17.5    -20.       5.\n",
      "    6.25     7.5      8.75    10.      11.25    12.5     13.75    15.\n",
      "   16.25    17.5     18.75    20.      21.25    22.5     23.75    25.     -15.\n",
      "  -22.5      1.25     2.5      3.75    -1.875  -11.875    1.875   16.875\n",
      "   18.125   19.375   -5.625   -6.875   -8.125   -9.375  -10.625  -13.125\n",
      "  -14.375  -15.625  -16.875  -18.125  -19.375    0.625    3.125    4.375\n",
      "    5.625    6.875    8.125    9.375   10.625   11.875   13.125   14.375\n",
      "   15.625   -0.625  -20.625  -21.875  -23.125   20.625   21.875   -3.125\n",
      "   -4.375   27.5     30.      32.5     35.      37.5     40.      42.5\n",
      "   45.      47.5     50.      26.25    28.75    31.25    33.75    36.25\n",
      "  -24.375  -27.5    -30.     -32.5    -35.     -36.25   -38.75   -41.25\n",
      "  -37.5    -42.5    -45.     -47.5    -50.      23.125   24.375  -48.75\n",
      "   38.75    41.25    43.75    46.25    48.75    52.5     56.25    60.\n",
      "   63.75    67.5     71.25    46.875  -25.625  -26.875  -28.125  -29.375\n",
      "  -30.625  -31.875   58.75   -43.75   -46.25   -53.75   -58.75   -63.75\n",
      "  -68.75   -75.     -80.     -52.5    -57.5    -61.25   -55.     -60.     -65.\n",
      "  -56.25    30.625   33.125   35.625   38.125  -33.125  -35.625  -38.125\n",
      "  -40.625  -43.125   25.625    0.5    -67.5    -71.25   -59.375  -61.875\n",
      "  -39.375  -41.875   34.375   26.875   31.875   39.375   43.125  129.375\n",
      "   97.5     64.375   69.375   48.125   29.375   36.875   41.875   53.75\n",
      "   68.75    73.75    78.75    83.75    88.75    40.625  -51.25    57.5\n",
      "   61.25    66.25    76.25    81.25    11.5      8.       2.   ]\n"
     ]
    }
   ],
   "source": [
    "class_names = Y.unique()\n",
    "print(class_names)\n",
    "\n",
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "   \n",
    "    print('Confusion matrix')\n",
    "\n",
    "    \n",
    "\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, cm[i, j],\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    \n",
    "#Price Change attribute below in matrix "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# grid search with cross-validation (subject-wise or k-folds) for picking hyperparameters\n",
    "# returns list with best estimators\n",
    "# params:\n",
    "# X_train - training data\n",
    "# y_train - labels\n",
    "# kfoldcv - true to use 10-fold cross-validation\n",
    "# display - boolean for printing out cross-validation info\n",
    "def grid(X_train,y_train, display=False, kfoldcv=False):\n",
    "    # Different models to try\n",
    "    #       Model name ---------------------------------------------------------------------\n",
    "    #      Parameters ------------------------------------------                           |\n",
    "    #     Classifier -----------                               |                           |\n",
    "    #                          |                               |                           |\n",
    "    #                          v                               v                           |\n",
    "    models = [[tree.DecisionTreeClassifier(), {'min_samples_split': [2, 4, 6, 8, 10],#    |\n",
    "                                               'min_samples_leaf': [1, 5, 10, 15, 20],#     v\n",
    "                                               'max_depth': [10, 20, 30, 40, 50]},       \"Decision Tree\"]\n",
    "              ]\n",
    "\n",
    "    models.append([linear_model.LogisticRegression(), {'C': [1e+4, 1e+3, 1e+2, 1e+1, 1, 1e-1, 1e-2, 1e-3, 1e-4, 1e-5]}, \"Logistic Regression with Ridge Penalty\"])\n",
    "\n",
    "#     models.append([linear_model.LogisticRegression(penalty='l1'), {'C': [100, 10, 1, 1e-1, 1e-2, 1e-3, 1e-4, 1e-5]}, \"Logistic Regression with Lasso Penalty\"])\n",
    "\n",
    "    # LinearSVC\n",
    "    models.append([svm.SVC(kernel='rbf'), { # class_weight=\"balanced\"; tol \n",
    "                              'gamma': [1e+4, 1e+3, 1e+2, 1e+1, 1, 1e-1, 1e-2, 1e-3, 1e-4, 1e-5, 1e-6], \n",
    "                               'C': [1e+4, 1e+3, 1e+2, 1e+1, 1, 1e-1, 1e-2, 1e-3, 1e-4, 1e-5, 1e-6]}, \"SVM rbf\"])\n",
    "    \n",
    "    models.append([neighbors.KNeighborsClassifier(), {'n_neighbors': [1, 3, 5, 7, 9, 11, 13, 15]}, \"K-Nearest Neighbors\"])\n",
    "\n",
    "\n",
    "    models.append([RandomForestClassifier(), {'n_estimators': [10, 20, 30, 40, 50, 60, 70, 80, 90, 100, 150, 200, 250, 300, 350, 400]\n",
    "                                               }, \"Random Forest\"])\n",
    "\n",
    "    models_with_best_params = []\n",
    "\n",
    "    # cross-validation strategy\n",
    "    # Leave One Group Out\n",
    "    groups = y_train.unique()\n",
    "    logo = LeaveOneGroupOut()\n",
    "    cv = logo.get_n_splits(X_train,y_train,groups)\n",
    "    \n",
    "    # for 10-folds cross-validation\n",
    "    if kfoldcv:\n",
    "        cv = 10 \n",
    "\n",
    "    for model in models:\n",
    "        clf = GridSearchCV(model[0], model[1], cv = cv)\n",
    "        clf.fit(X_train, y_train)\n",
    "        best_params = clf.best_params_\n",
    "        best_estimator = clf.best_estimator_\n",
    "\n",
    "        model_with_best_params = [best_estimator, best_params, model[2]]\n",
    "\n",
    "        models_with_best_params.append(model_with_best_params)\n",
    "\n",
    "        if (display):\n",
    "            print(model[2], \": \")\n",
    "            print(\"Best score for \", model[2], \":\", clf.best_score_)\n",
    "            print()\n",
    "            print(\"Best parameters for \", model[2], \" found on development set:\", best_params)\n",
    "    #         print()\n",
    "    #         print(\"Best estimator for \", model[2], \" model:\", best_estimator)\n",
    "            print()\n",
    "    #         print()\n",
    "\n",
    "    #         print(\"Grid scores on development set:\")\n",
    "    #         print()\n",
    "    #         for params, mean_score, scores in clf.grid_scores_:\n",
    "    #             print(\"%0.3f (+/-%0.03f) for %r\"\n",
    "    #                   % (mean_score, scores.std() * 2, params))\n",
    "            print()\n",
    "\n",
    "    #     print(models_with_best_params)\n",
    "    \n",
    "#     return best_params['n_estimators']\n",
    "    return  models_with_best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def test_classifier (model, X_train, y_train, X_test, y_test):\n",
    "#     classifier = RandomForestClassifier(n_estimators=pram)\n",
    "    classifier = model[0]\n",
    "    classifier.fit(X_train, y_train)\n",
    "    score = classifier.score(X_test, y_test)\n",
    "    #print(\"Prediction accuracy for\", model[2], \"model is\", score)\n",
    "    expected = y_test\n",
    "    predicted = classifier.predict(X_test)\n",
    "\n",
    "    print(\"Classification report for classifier %s:\\n%s\\n\"\n",
    "      % (classifier, metrics.classification_report(expected, predicted, digits=5)))\n",
    "    #Compute confusion matrix\n",
    "    cnf_matrix = confusion_matrix(expected, predicted)\n",
    "    np.set_printoptions(precision=2)\n",
    "\n",
    "    # Plot non-normalized confusion matrix\n",
    "    plt.figure()\n",
    "    plot_confusion_matrix(cnf_matrix, classes=class_names,\n",
    "    title='Confusion matrix, without normalization: ' + model[2])\n",
    "\n",
    "    plt.show()\n",
    "    \n",
    "    return [metrics.f1_score(expected,predicted, average='weighted'), cnf_matrix]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 10-fold cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_test_split' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-5ba6901e56aa>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.30\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m50\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Train Set Size: \"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Test Set Size: \"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mfeatures\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mselect_features\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'train_test_split' is not defined"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.30, random_state=50)\n",
    "print(\"Train Set Size: \", len(X_train))\n",
    "print(\"Test Set Size: \", len(X_test))\n",
    "\n",
    "features = select_features(X_train, y_train)\n",
    "X_train = X_train[features]\n",
    "print(\"Train set size after feature selection: \", X_train.shape)\n",
    "X_test = X_test[features]\n",
    "print(\"Test set size after feature selection: \", X_test.shape)\n",
    "\n",
    "#Split 70/30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'LeaveOneGroupOut' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-127-fc13b37c785c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mbest_classifiers\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgrid\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-79-fbcc962934ab>\u001b[0m in \u001b[0;36mgrid\u001b[1;34m(X_train, y_train, display, kfoldcv)\u001b[0m\n\u001b[0;32m     38\u001b[0m     \u001b[1;31m# Leave One Group Out\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     39\u001b[0m     \u001b[0mgroups\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munique\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 40\u001b[1;33m     \u001b[0mlogo\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mLeaveOneGroupOut\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     41\u001b[0m     \u001b[0mcv\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlogo\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_n_splits\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mgroups\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     42\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'LeaveOneGroupOut' is not defined"
     ]
    }
   ],
   "source": [
    "best_classifiers = grid(X_train, y_train, True, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'best_classifiers' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-128-ef90f903d667>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#fitting models to test_data#fitting\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[1;32mfor\u001b[0m \u001b[0mmodel\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mbest_classifiers\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m     \u001b[0mtest_classifier\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'best_classifiers' is not defined"
     ]
    }
   ],
   "source": [
    "#fitting models to test_data#fitting \n",
    "for model in best_classifiers:\n",
    "    test_classifier (model, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# subject-wise cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Get confusion matrix\n",
    "#Fix classifiers in separate file "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Random Forest \n",
    "#Linear Regression\n",
    "#Logistic Regression\n",
    "#SVM\n",
    "#Maybe KNN and Decision trees, but not a priority rn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'datasets' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-47569d875fa0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Load digits data from 'datasets module'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mdigits\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdatasets\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_digits\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0msvr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msvm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSVC\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkernel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'rbf'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mparameters\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;34m'C'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'gamma'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mg\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'datasets' is not defined"
     ]
    }
   ],
   "source": [
    "# Load digits data from 'datasets module'\n",
    "digits = datasets.load_digits()\n",
    "svr = svm.SVC(kernel='rbf')\n",
    "parameters = {'C':c, 'gamma': g}\n",
    "\n",
    "n_samples = np.round(len(digits.data)/2)\n",
    "\n",
    "#   Get data-records and record-labels in arrays X and y\n",
    "X_training=digits.data[:n_samples]\n",
    "y_training=digits.target[:n_samples]\n",
    "\n",
    "#   Get data-records and record-labels in arrays X and y\n",
    "X_testing=digits.data[n_samples:]\n",
    "y_testing=digits.target[n_samples:]\n",
    "\n",
    "#clf = grid_search.GridSearchCV(knearest, parameters, cv=10)\n",
    "clf = grid_search.GridSearchCV(svr, parameters)\n",
    "\n",
    "#clf = svm.SVC(kernel='poly', gamma=1) \n",
    "clf.fit(X_training, y_training)\n",
    "\n",
    "# Make class predictions for all observations in X_testing\n",
    "Z = clf.predict(X_testing)\n",
    "\n",
    "# Compare predicted class labels with actual class labels\n",
    "accuracy=clf.score(X_testing,y_testing)\n",
    "print (\"Predicted model accuracy: \"+ str(accuracy))\n",
    "print (clf.best_params_['C'])\n",
    "print (clf.best_params_['gamma'])\n",
    "print (clf.get_params())\n",
    "print (cross_validation.cross_val_score(clf, X_testing, y_testing))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def test_classifier (model, X_train, y_train, X_test, y_test):\n",
    "#     classifier = RandomForestClassifier(n_estimators=pram)\n",
    "    classifier = model[0]\n",
    "    classifier.fit(X_train, y_train)\n",
    "    score = classifier.score(X_test, y_test)\n",
    "    #print(\"Prediction accuracy for\", model[2], \"model is\", score)\n",
    "    expected = y_test\n",
    "    predicted = classifier.predict(X_test)\n",
    "\n",
    "    print(\"Classification report for classifier %s:\\n%s\\n\"\n",
    "      % (classifier, metrics.classification_report(expected, predicted, digits=5)))\n",
    "    #Compute confusion matrix\n",
    "    cnf_matrix = confusion_matrix(expected, predicted)\n",
    "    np.set_printoptions(precision=2)\n",
    "\n",
    "    # Plot non-normalized confusion matrix\n",
    "    plt.figure()\n",
    "    plot_confusion_matrix(cnf_matrix, classes=class_names,\n",
    "    title='Confusion matrix, without normalization: ' + model[2])\n",
    "\n",
    "    plt.show()\n",
    "    \n",
    "#Split data 60/40\n",
    "#Run 60% through classifiers and then test on the remaining 40% to see which produced highest accuracy results\n",
    "\n",
    "#What is this one's accuracy?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'datasets' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-e6e50471d178>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Load digits data from 'datasets module'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mdigits\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdatasets\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_digits\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m10.0\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mn_samples\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mround\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdigits\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m/\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mparameters\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;34m'C'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mc\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'datasets' is not defined"
     ]
    }
   ],
   "source": [
    "# Load digits data from 'datasets module'\n",
    "digits = datasets.load_digits()\n",
    "c = 10.0**np.arange(-5,5)\n",
    "n_samples = np.round(len(digits.data)/2)\n",
    "parameters = {'C':c,}\n",
    "\n",
    "#   Get data-records and record-labels in arrays X and y\n",
    "X_training=digits.data[:n_samples]\n",
    "y_training=digits.target[:n_samples]\n",
    "\n",
    "#   Get data-records and record-labels in arrays X and y\n",
    "X_testing=digits.data[n_samples:]\n",
    "y_testing=digits.target[n_samples:]\n",
    "\n",
    "svr = LogisticRegression(penalty='l1')\n",
    "\n",
    "# Create an instance of KNeighborsClassifier and then fit training data\n",
    "clf = grid_search.GridSearchCV(svr, parameters)\n",
    "\n",
    "#clf = LogisticRegression(C=1.0, dual=False, fit_intercept=True,intercept_scaling=1, penalty='l2', tol=0.0001)\n",
    "clf.fit(X_training, y_training)\n",
    "\n",
    "# Make class predictions for all observations in X_testing\n",
    "Z = clf.predict(X_testing)\n",
    "\n",
    "# Compare predicted class labels with actual class labels\n",
    "accuracy=clf.score(X_testing,y_testing)\n",
    "print (\"Predicted model accuracy: \"+ str(accuracy))\n",
    "print (clf.best_params_['C'])\n",
    "print (clf.get_params())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
